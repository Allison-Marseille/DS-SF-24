{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Folium Test Program\n",
    "# To install folium to your computer run the following:\n",
    "# conda install --channel https://conda.anaconda.org/conda-forge folium\n",
    "# We will also want to install shapely to do a bit of geocoding, so to install this run:\n",
    "# conda install shapely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import urllib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_osm = folium.Map(location=[37.79086, -122.40147], zoom_start=14)\n",
    "folium.Marker([37.79086, -122.40147], popup='General Assembly').add_to(map_osm)\n",
    "map_osm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_geo_url(url):\n",
    "    in_file = urllib.urlopen(url)\n",
    "    return json.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_url = 'https://raw.githubusercontent.com/python-visualization/folium/master/examples/us-states.json'\n",
    "state_geo = read_geo_url(state_url)\n",
    "state_unemployment = (\n",
    "    r'https://raw.githubusercontent.com/python-visualization/folium/master/examples/US_Unemployment_Oct2012.csv')\n",
    "\n",
    "state_data = pd.read_csv(state_unemployment)\n",
    "\n",
    "state_data.head()\n",
    "\n",
    "# To view json go to the following link:\n",
    "# https://raw.githubusercontent.com/python-visualization/folium/master/examples/us-states.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let Folium determine the scale and view Choropleth\n",
    "states = folium.Map(location=[40, -102], zoom_start=4)\n",
    "states.choropleth(geo_str=state_geo, data=state_data,\n",
    "                columns=['State', 'Unemployment'],\n",
    "                key_on='feature.id',\n",
    "                fill_color='YlGn', fill_opacity=0.7, line_opacity=0.2,\n",
    "                legend_name='Unemployment Rate (%)')\n",
    "states\n",
    "# To load a choropleth map from your hard drive use geo_path (i.e.)\n",
    "# states.choropleth(geo_path='states.geojson', data=state_data,\n",
    "#                columns=['State', 'Unemployment'], \n",
    "#                key_on='feature.id',\n",
    "#                fill_color='YlGn', fill_opacity=0.7, line_opacity=0.2,\n",
    "#                legend_name='Unemployment Rate (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with a more local version \n",
    "\n",
    "A topic near and dear to my heart, human feces in San Francisco\n",
    "\n",
    "View this map published by the amazing William Mees. https://willyem.carto.com/viz/156b1e0c-5b45-11e5-9351-0e018d66dc29/public_map\n",
    "\n",
    "http://www.citylab.com/housing/2015/10/mapping-san-franciscos-sidewalk-pooping-problem/409561/\n",
    "\n",
    "My plan for this exercise is to import \n",
    "in the GeoJson file for human feces over the last few years \n",
    "in San Francisco, as a way to visualize how the data is spread out over the years.\n",
    "\n",
    "I will also be using a San Francisco geojson map of neighborhoods, and combining this with a dataset of excrement sightings to visualize it as an aggregate of data per neighborhood.\n",
    "\n",
    "I will first just show a simple map of the points shown in the data set that William gathered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poop_url = r\"https://raw.githubusercontent.com/joshuacano/DS-SF-24/master/folium_lecture/2010_poop.json\"\n",
    "poop_data = read_geo_url(poop_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's look at the first poop instance!\n",
    "poop_data['features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(poop_data['features'])\n",
    "\n",
    "# We should only use 500 observations as folium will stall ipython with any more points\n",
    "poop_data['features'] = poop_data['features'][:500] \n",
    "poop_map = folium.Map(location=[37.79086, -122.40147], zoom_start=12)\n",
    "poop_map.choropleth(geo_str=poop_data)\n",
    "poop_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Lets overlay that with some neighborhood shapes.\n",
    "# I took this data from code america. Thanks Code America!\n",
    "# https://github.com/codeforamerica/click_that_hood/blob/master/public/data/san-francisco.geojson\n",
    "\n",
    "sf_path='https://raw.githubusercontent.com/joshuacano/DS-SF-24/master/folium_lecture/san-francisco.geojson'\n",
    "hood_json = read_geo_url(sf_path)\n",
    "\n",
    "#Add style attributes\n",
    "my_style = {\n",
    "    \"color\": \"#ff7800\",\n",
    "    \"weight\": 2,\n",
    "    \"opacity\": 0.65\n",
    "}\n",
    "folium.GeoJson(hood_json,\n",
    "               style_function=lambda x: my_style, overlay=True).add_to(poop_map)\n",
    "\n",
    "poop_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Okay, so this looks a little bit funky. But its got some good information on it, \n",
    "so lets try and aggregate all this data together using pandas!\n",
    "\n",
    "First, lets read our data into a dataframe and get the details we need from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Seems like we will want the point, the date it was opened, the casid, \n",
    "# the neighborhood, and the supervisor_district, that could be interesting!\n",
    "def get_details(item):\n",
    "    details = {}\n",
    "    details['point'] = item['geometry']['coordinates']\n",
    "    details['date_opened'] = item['properties']['opened']\n",
    "    details['caseid'] = item['properties']['caseid']\n",
    "    details['neighborhood'] = item['properties']['neighborhood']\n",
    "    details['supervisor_district'] = item['properties']['supervisor_district']\n",
    "    return details\n",
    "\n",
    "poop_url = r\"https://raw.githubusercontent.com/joshuacano/DS-SF-24/master/folium_lecture/2010_poop.json\"\n",
    "poop_data = read_geo_url(poop_url)\n",
    "\n",
    "rs = []\n",
    "for incident in poop_data['features']:\n",
    "    rs.append(get_details(incident))\n",
    "poop_frame = pd.DataFrame(rs)\n",
    "print len(poop_frame)\n",
    "poop_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poop_frame.groupby(['neighborhood']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# K so it seems like we have a much bigger amount of neighborhoods in the incident data,\n",
    "# than in our neighborhood layer. \n",
    "# lets try and match each incident to the existing neighborhood layer we got.\n",
    "# For that we will use the shapely library we just downloaded.\n",
    "import shapely.geometry\n",
    "point = shapely.geometry.Point (poop_frame.point[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print datetime.now()\n",
    "hood_shapes = []\n",
    "\n",
    "for feature in hood_json[\"features\"]:\n",
    "    hood_shapes.append({\n",
    "            \"shape\" : shapely.geometry.shape(feature[\"geometry\"]),\n",
    "             \"name\" : feature['properties']['name']})\n",
    "    \n",
    "\n",
    "poop_frame['shape_neighborhood'] = None\n",
    "for hood_shape in hood_shapes:\n",
    "    for row in poop_frame.loc[poop_frame['shape_neighborhood'].isnull(),:].itertuples():\n",
    "        point = shapely.geometry.Point(row.point)\n",
    "        # This will check to see if the incident was in the neighborhood\n",
    "        if hood_shape['shape'].contains(point):\n",
    "            poop_frame.loc[row[0], 'shape_neighborhood'] = hood_shape['name']\n",
    "print datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ok so now that we know how to match an incident with our existing neighborhood geojson file,\n",
    "# lets make a new dataframe that has all the neighborhoods with their frequency per neighborhood \n",
    "freq_frame = poop_frame.groupby(['shape_neighborhood']).count()\n",
    "freq_frame['shape_neighborhood'] = freq_frame.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In case we have some points not in neighborhoods lets setup a default case\n",
    "def fill_with_default(hood_shapes, frame):\n",
    "    default_frame = pd.DataFrame(hood_shapes)\n",
    "    default_frame['caseid'] = 0 \n",
    "    default_frame['shape_neighborhood'] = default_frame['name']\n",
    "    del default_frame['shape']\n",
    "    default_frame.set_index(['name'], inplace=True)\n",
    "    default_frame.update(frame)\n",
    "    default_frame.caseid = default_frame.caseid.astype(int)\n",
    "    return default_frame\n",
    "\n",
    "freq_frame = fill_with_default(hood_shapes, freq_frame)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now lets associate it with our original neighborhood map.\n",
    "poop_map = folium.Map(location=[37.79086, -122.40147], zoom_start=12)\n",
    "poop_map.choropleth(geo_str=hood_json,\n",
    "                    data=freq_frame,\n",
    "                columns=['shape_neighborhood', 'caseid'],\n",
    "                key_on='feature.properties.name',\n",
    "                fill_color='YlOrRd', fill_opacity=0.7, line_opacity=0.2,\n",
    "                legend_name='Poop Frequency')\n",
    "poop_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can see the automated legend is thrown off by the outliers, lets send in our own legend\n",
    "poop_map = folium.Map(location=[37.79086, -122.40147], zoom_start=12)\n",
    "poop_map.choropleth(geo_str=hood_json,\n",
    "                    data=freq_frame,\n",
    "                columns=['shape_neighborhood', 'caseid'],\n",
    "                threshold_scale=[5,20,40,60,80, 400],\n",
    "                key_on='feature.properties.name',\n",
    "                fill_color='YlOrRd', fill_opacity=0.7, line_opacity=0.2,\n",
    "                legend_name='Poop Frequency')\n",
    "\n",
    "poop_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_daterange(start_date, end_date, frame):\n",
    "    \"\"\"In case anyone wants to cut the data by start and end_date\"\"\"\n",
    "    df = frame.groupby(['shape_neighborhood']).count()\n",
    "    df.caseid = 0\n",
    "    date_frame = frame[(frame.date_opened >= start_date) &\n",
    "                       (frame.date_opened < end_date)]\n",
    "    date_frame = date_frame.groupby(['shape_neighborhood']).count()['caseid']\n",
    "    df.update(date_frame)\n",
    "    df.caseid = df.caseid.astype(int)\n",
    "    df['shape_neighborhood'] = df.index\n",
    "    return df\n",
    "\n",
    "def get_threshold_scale(frame, column):\n",
    "    \"\"\"In case you want to have a customized Threshold scale for the dataFrame\n",
    "    \n",
    "    We will use a larger than normal range for the first 4 scales.\n",
    "    In order to get some more separation for the tiles\"\"\"\n",
    "    rs = []\n",
    "    for i in np.linspace(0.2, 0.95, 6, endpoint=True):\n",
    "        rs.append(frame[frame[column] >0][column].quantile(i))\n",
    "    return rs\n",
    "\n",
    "poop_map = folium.Map(location=[37.79086, -122.40147], zoom_start=12)\n",
    "poop_map.choropleth(geo_str=hood_json,\n",
    "                    data=freq_frame,\n",
    "                columns=['shape_neighborhood', 'caseid'],\n",
    "                threshold_scale=(get_threshold_scale(freq_frame, 'caseid')),\n",
    "                key_on='feature.properties.name',\n",
    "                fill_color='YlOrRd', fill_opacity=0.7, line_opacity=0.2,\n",
    "                legend_name='Poop Frequency')\n",
    "\n",
    "poop_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
